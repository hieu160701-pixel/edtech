import streamlit as st
import google.generativeai as genai
import pandas as pd

# 1. C·∫§U H√åNH TRANG WEB
st.set_page_config(page_title="Tr·ª£ l√Ω Gi√°o d·ª•c AI", page_icon="üéì")

st.title("üéì AI Coach - T√¨m l·ªô tr√¨nh h·ªçc chu·∫©n x√°c")
st.write("Ch√†o b·∫°n, t√¥i s·∫Ω gi√∫p b·∫°n t√¨m kh√≥a h·ªçc ph√π h·ª£p nh·∫•t thay v√¨ t√¨m ki·∫øm m·ªát m·ªèi tr√™n Google.")

# 2. K·∫æT N·ªêI API & D·ªÆ LI·ªÜU
# L·∫•y API Key b√≠ m·∫≠t t·ª´ c·∫•u h√¨nh c·ªßa Streamlit
try:
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    else:
        st.error("Ch∆∞a c·∫•u h√¨nh API Key trong Secrets. Vui l√≤ng v√†o C√†i ƒë·∫∑t (Advanced Settings) tr√™n Streamlit Cloud v√† th√™m `GEMINI_API_KEY`.")
        st.stop()
    
    # --- PH·∫¶N B·∫†N C·∫¶N S·ª¨A LINK CSV ---
    # Thay ƒë∆∞·ªùng link b√™n d∆∞·ªõi b·∫±ng link CSV b·∫°n l·∫•y ·ªü B∆Ø·ªöC 1
    # Link n√†y d√πng ƒë∆∞·ª£c cho c·∫£ "Publish to Web" v√† "Share with anyone link"
    csv_url = "https://docs.google.com/spreadsheets/d/1Ql3qgm_zU3X8mSUfabL0J1vg4Ctu6OUzz4Q0Z-R8_Jc/export?format=csv"
    
    # ƒê·ªçc d·ªØ li·ªáu
    df = pd.read_csv(csv_url)
    
except Exception as e:
    st.error(f"L·ªói k·∫øt n·ªëi: {e}. \\n\\n**L∆∞u √Ω quan tr·ªçng:**\\n1. Ki·ªÉm tra xem b·∫°n ƒë√£ 'Publish to Web' file Google Sheet ch∆∞a?\\n2. Ki·ªÉm tra API Key c√≥ ƒë√∫ng kh√¥ng?")
    st.stop()

# 3. GIAO DI·ªÜN CHAT
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "model", "content": "Ch√†o b·∫°n! B·∫°n ƒëang mu·ªën h·ªçc k·ªπ nƒÉng g√¨? (V√≠ d·ª•: T√¥i mu·ªën h·ªçc Marketing ƒë·ªÉ t·ª± b√°n h√†ng online)"}
    ]

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat c≈©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. X·ª¨ L√ù KHI NG∆Ø·ªúI D√ôNG NH·∫¨P LI·ªÜU
if prompt := st.chat_input("Nh·∫≠p m·ª•c ti√™u h·ªçc t·∫≠p c·ªßa b·∫°n..."):
    # Hi·ªán c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # G·ª≠i y√™u c·∫ßu cho AI
    with st.chat_message("model"):
        with st.spinner("ƒêang ph√¢n t√≠ch l·ªô tr√¨nh ph√π h·ª£p..."):
            try:
                # Chuy·ªÉn d·ªØ li·ªáu Excel th√†nh vƒÉn b·∫£n ƒë·ªÉ AI ƒë·ªçc
                data_text = df.to_string()
                
                # C√¢u l·ªánh ƒëi·ªÅu khi·ªÉn AI (System Prompt)
                full_prompt = f"""
                Vai tr√≤: B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n gi√°o d·ª•c t·∫≠n t√¢m.
                
                D·ªØ li·ªáu kh√≥a h·ªçc c√≥ s·∫µn (ch·ªâ ƒë∆∞·ª£c gi·ªõi thi·ªáu trong danh s√°ch n√†y):
                {data_text}
                
                Y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng: "{prompt}"
                
                Nhi·ªám v·ª•:
                1. Ph√¢n t√≠ch xem ng∆∞·ªùi d√πng ƒëang thi·∫øu k·ªπ nƒÉng g√¨.
                2. ƒê·ªÅ xu·∫•t m·ªôt l·ªô tr√¨nh h·ªçc ng·∫Øn g·ªçn.
                3. QUAN TR·ªåNG: Ch·ªçn ra 1-2 kh√≥a h·ªçc trong danh s√°ch tr√™n ph√π h·ª£p nh·∫•t.
                4. B·∫Øt bu·ªôc ph·∫£i ƒë∆∞a ra Link Affiliate c·ªßa kh√≥a h·ªçc ƒë√≥ ƒë·ªÉ ng∆∞·ªùi d√πng click.
                5. Gi·ªçng vƒÉn th√¢n thi·ªán, khuy·∫øn kh√≠ch.
                """
                
                # Danh s√°ch c√°c model ƒë·ªÉ th·ª≠ (d·ª± ph√≤ng khi model n√†y l·ªói th√¨ qua model kh√°c)
                # Danh s√°ch c√°c model ƒë·ªÉ th·ª≠ (Ch·ªâ d√πng c√°c key ƒë√£ ki·ªÉm tra l√† c√≥ s·∫µn)
                models_to_try = [
                    'gemini-2.0-flash',             # B·∫£n ·ªïn ƒë·ªãnh
                    'gemini-2.0-flash-lite',        # B·∫£n nh·∫π
                    'gemini-2.0-flash-exp',         # B·∫£n th·ª≠ nghi·ªám (th∆∞·ªùng √≠t b·ªã limit)
                    'gemini-flash-latest',          # Alias tr·ªè v·ªÅ b·∫£n flash m·ªõi nh·∫•t (th∆∞·ªùng l√† 1.5)
                ]
                
                response = None
                error_log = []
                
                for model_name in models_to_try:
                    try:
                        # Th√™m delay nh·ªè ƒë·ªÉ tr√°nh spam request qu√° nhanh l·ªói 429 li√™n ho√†n
                        import time
                        time.sleep(1) 
                        model = genai.GenerativeModel(model_name)
                        response = model.generate_content(full_prompt)
                        break
                    except Exception as e:
                        error_log.append(f"{model_name}: {str(e)}")
                        continue
                
                if response:
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "model", "content": response.text})
                else:
                    error_details = "\\n".join(error_log)
                    st.error(f"H·ªá th·ªëng ƒëang r·∫•t b·∫≠n. ƒê√£ th·ª≠ t·∫•t c·∫£ c√°c models nh∆∞ng ƒë·ªÅu th·∫•t b·∫°i:\\n{error_details}\\n\\nVui l√≤ng ƒë·ª£i 1 ph√∫t v√† th·ª≠ l·∫°i.")
                
            except Exception as e:
                st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra: {e}")
